## 内容安全基本介绍

### 参考资料链接

[互联网内容安全知识库](https://www.yuque.com/wuxianfeng/uvyeb4)

[如何建设内容安全数据指标体系？（上篇） (yuque.com)](https://www.yuque.com/wuxianfeng/uvyeb4/is4ys1)

[如何建设内容安全数据指标体系？（下篇） (yuque.com)](https://www.yuque.com/wuxianfeng/uvyeb4/foihnl)

阿里：[内容安全产品功能_内容安全-阿里云帮助中心 (aliyun.com)](https://help.aliyun.com/document_detail/28417.html?spm=a2c4g.28415.0.0.1b2c115a4iwabY)

百度：[内容审核平台 - 简介 | 百度AI开放平台 (baidu.com)](https://ai.baidu.com/ai-doc/ANTIPORN/Vk3h6xaga)

腾讯：[内容安全_人工审核_一站式内容审核 (tencent.com)](https://cloud.tencent.com/solution/content-security)

字节：

- [音视频内容安全--实时音视频-火山引擎 (volcengine.com)](https://www.volcengine.com/docs/6348/1140990)
- [内容质检--内容管理平台-火山引擎 (volcengine.com)](https://www.volcengine.com/docs/6440/124179)

谛听：[文本检测_帮助文档-行者AI谛听 (xingzheai.cn)](https://ting.xingzheai.cn/help/guide/text)

### 什么是内容安全？

内容安全指的是对互联网中涉政、涉黄、涉暴恐等敏感性内容的治理，也有涉及对广告的识别和治理。

治理内容的大类包括：视频、音频、图像、文本

> 我个人理解，图像和文本是主要的内容
>
> 因为视频可以通过抽帧的方式转换为图像
>
> 然后可以从视频中提取音频，音频又可以转换为文本

### 内容安全的难点有哪些？

**技术难点**

- **多样性和复杂性**：影音图文，每个大类底下还有细分。
- **算法能力**：算法模型越多、越大、速度效率越低。越小，越简单，准确率越低。
- **规模问题**：数据量特别大，每天可能需要处理数以亿计的内容项。
- **实时性要求**：视频直播、弹幕互动
- **上下文敏感性**：某些内容是否违规可能取决于特定的文化或语境，这增加了识别的复杂性。（比如说食指比“耶”，在英国有侮辱含义）

**法律伦理难点**

- **隐私保护**：内容安全很重要，用户的隐私也很重要（网盘里的文档、图片，网盘服务提供商是否有权扫描删除？）
- **言论自由**：今年马斯克和BBC记者的一个辩论就提到 仇恨言论和言论自由。

**具体实施和管理**

- **人力资源**：机器审核无法满足所有场景，可能需要人审介入。
- **多部门协作**：对内要协调算法，与产品进行沟通。对外要对接客户，沟通了解需求。



**素材内容审核效率低**：海量素材全量人工送审，成本高昂不可控。

**违规内容对抗激烈**：”擦边球“类型的违规内容层出不穷，传统机器审核难以甄别。

**政策感知策略调整不及时**：监管政策实时变动，策略调整把握不到位。

> 举例1：之前不禁比特币，公开讨论炒币、买币不会被封禁。但是监管政策变了，审核策略也得立刻跟上。
>
> 举例2：之前大胃王的视频层出不穷，国家后来出台了法规认为这类内容有浪费粮食的倾向。
>
> 举例3：比如英烈保护法发布后查出暴走漫画、今日头条侮辱英烈；

**人审团队管理成本高**：人工审核人员不稳定，培训成本高，导致企业管理成本不可控。

### 机器审核和人工审核的对比

现在对于内容安全的风险管控和治理，主要是机器审核+人工审核。

机器审核的优点：

- 规模大：能够同时对大量的内容进行审核。
- 速度快：机器审核单个样本的速度相对于人工会更快。
- 成本低：一旦建立好机器审核系统，机器审核系统成本相对于人工审核的培训成本、人力管理成本会更低。

人工审核的优点：

- 高准确性：对于复杂或模糊的内容，做的比机器好。比如一些讽刺的内容，人工可以识别，机器不一定能够识别，比如正话反说（对一个个子矮的人说，你长得真高）。

二者结合以后的优点：

- 降本：机器可以帮助过滤掉哪些明显危险的内容，减少审核员压力。
- 准确率提升：对于机器无法识别的模糊内容，通过人工把关。能够提升内容审核的准确率。
- 持续优化：人工审核的结果，反映了机器审核的错判漏判行为，从而我们可以进一步去优化机器的算法。

### 内容审核的关键指标

**准确率**：模型正确识别 / 送检数据总量 x 100%

该指标比较简单，但是一般情况下坏样本（内容违规的样本）的比例是比较小的，还需要其他指标来衡量模型的能力。

**召回率**：模型正确识别坏样本数量 / 送检数据坏样本总量 x 100%

指标越高，说明漏网置之鱼越少。

**误召率**：模型错误识别坏样本数量 / 送检数据好样本总量 x 100%

这个指标越高，说明有越多的样本被”误杀“了。

**单笔审核处理响应时间**：不考虑并发的情况下，从审核请求发出，到审核结果返回所消耗的时间。

**QPS**：Queries Per Second，每次查询所花费的时间。

### 如何改善内容审核效果？

机审遗漏=机审通过，但人工审核不通过；

机审误伤=机审不通过，但人工审核通过；

- **黑名单、白名单**：对于经常误报的情况，可以添加白名单。对应地，漏报的情况可以添加黑名单。（白名单，比如欧洲一些中世纪的艺术画作，有身体裸露的现象。）
- **调节风险阈值**：因为就我了解，内容识别出来是一个个风险标签以及对应标签的风险评分（比如0~100分），可以适当调节风险阈值来改善漏报、误报的现象。
- **样本扩充，实时更新**：对于一些新型的暗语，或者规避的方式，补充进关键词库。同时也可以对算法的训练样本作增强，扩充样本量。
- **用户反馈机制**：刚刚说的样本扩充属于自检，方案上线后，可能也需要一些用户反馈机制，比如误封的用户，他可能会去申诉。漏封的内容可能会被其他用户举报。
- **多层次审核**：对于一个场景，希望机器审核就能解决，如果不行，可能还是需要引入人工审核的方式。此外，或许可以使用多个模型或多个审核层次来减少遗漏。
- **算法优化**：这个我认为短时间内不太现实，而且这项工作可能还是主要交给算法的同学去做。如果举例子的话，比如模型蒸馏，比较参数量较大、复杂程度更高的模型，这种模型速度也更慢，但是精准度会更好。利用这些模型来指导稍简单、但是效率更高的模型进行优化。

有的情况下，可能没有人审的资源怎么办？

细分的模型，针对某种场景特殊训练的模型，利用这些模型来打标。

历史的相似的场景借鉴，如果之前有积累过类似的场景的数据。

社会热点、紧急事件的应对

突发性的事件：比如之前南京的新街口砍人事件，一开始视频还可以发，过大概2、3个小时左右，视频一发就被删除了。

> 我猜可能是用了视频的MD5码

### 如何验证智能内容审核系统与产品业务的匹配度？

- 准备超过1000个的数据样本（超过1000个数据后各个指标精度为0.1%）
- 采用标准算法进行机器审核，获得机审通过数量和机审不通过数量；
- 采用业务审核标准进行人工审核，获得正常数据量和违规数据量；
- 对比机器审核和人工审核结果，获得以下数据：
  - 机审通过=机审通过，且人工审核通过；
  - 机审误伤=机审不通过，但人工审核通过；
  - 机审命中=机审不通过，且人工审核不通过；
  - 机审遗漏=机审通过，但人工审核不通过；
- 智能内容审核系统业务匹配度分析：
  - 准确率=（机审通过+机审命中）/总数据量，该指标越高说明模型出错的概率越低；
  - 误召率=机审误伤/正常数据量，该指标越高说明误伤用户的概率越高；
  - 召回率=机审命中/违规数据量，该指标越高说明遗漏坏样本的概率越低。

> 我的理解是先用一些样本来验证目前的审核系统对于这种场景能不能有比较好的适用性。
>
> 如果不行，再针对误召样本、遗漏样本进行针对性的分析。

如何调整智能内容审核系统运营模式提升业务匹配度？
1、根据算法模型置信率，调整审核通过标准；
2、细分算法模型，用最小算法模型组合匹配业务特性；
3、定制运营工具，结合算法模型进行审核，提高业务匹配度；
4、其他。

### 日常审核中容易遗漏的点

[内容安全 - 知乎 (zhihu.com)](https://www.zhihu.com/column/c_1545731492273369088)

**字符盖楼形式的违规**。比如用字符拼成一个违规的图案。这种是比较难的，它不仅依赖文字本身，还依赖文字的排列组合。

> 如何解决，容易想到的是把文字转换为图像，在应用图像识别。
>
> 但是这样的话每个评论都要转换，成本太大了
>
> 可以先识别这个评论是不是盖楼形式的评论。有挺多特征，比如每一行的字符数量相同、使用了大量一样的字符。内容本身没有意义等等。
>
> 识别出来后，再将文本转换为图片，应用图像识别。

**藏头诗**

> 可以采用提特征的方式，提取句首的每一个字，进行文本识别

**影射、暗喻**等。

> 需要AI模型来进行句意的识别。

在内容审核中，总有一些疏忽，犯下无心之过，导致内容安全问题。就此，谛听安全内容审核团队分享了日常审核中最容易疏漏的点，希望能帮到大家：

1、图片中与背景色相似的水印（微信、联系方式等），未察觉；

2、相同的刷屏内容，未处理干净；

3、垃圾信息分拆多条发送，单条无问题；

4、短链、外链跳转后违规；

5、OCR违规，图片旋转等；

6、涉政、色情、违禁的网络用语或者黑话（419、上车等）；

7、政治人物被查后，全信息扫描；

8、隐晦的推广行为（非明确的联系方式、广告词）；

9、藏头诗、藏尾诗包含违规内容；

10、没有多维度拦截监控有害信息，昵称、头像、评论或者注册行为IP、设备ID、手机号等；

11、色情番号判断；

12、小语种有害信息；

13、特定圈子的特定名词（耽美、BL、SM、幼齿、慕残等）；

14、多图组合违规；

15、联系方式变形（阿拉伯、字母、繁体字）；

16、盖楼形式的违规字符图；

17、直播中不经意拍摄到违规内容（类似于香港旅游拍摄到FLG）；

18、旗帜、地图、产地等易被疏忽的细节涉及分裂国家；

19、干扰词、变形词易漏；

20、通过内容引导到其他平台，从其他平台进行违规行为；

21、头像有问题处理后，该用户的昵称及其他UGC内容被遗漏，没有全方位处理；

22、未紧跟监管规则，被监管部门打时间差，比如英烈保护法发布后查出暴走漫画、今日头条侮辱英烈；

23、影射、色情暗喻等图片或文字，易漏过。

### 怎么针对账号主体进行内容安全风险管控？

基础的数据收集：

- **账号基础信息**：注册时间、活跃度
- **自身内容数据**：发布的文本、图片、视频等内容。
- **社交行为**：点赞、转发、关注、粉丝数等
- **用户反馈**：别人有没有对他进行举报，历史违规记录。

账户内容风险特征构建

- **内容风险特征**：使用自然语言处理和图像识别等技术，分析发布内容的风险等级。
- **行为风险特征**：异常的社交互动模式，如短时间内大量转发。
- **信誉特征**：基于用户反馈和历史违规记录来评估账号的信誉。
- **社交网络分析**：分析账号在社交网络中的位置和作用，如是否与已知的高风险账号有联系。
- **设备分析**：分析内容违规来源IP是否有群聚性，使用的设备是否是真实设备。



## 内容安全解决方案

### 场景接入

在基础建设上要做好场景的细分、内容的细分、以及安全等级的细分，这样的目的是为之后差异化的接入管控策略

建立应急响应能力，尤其是涉政场景的处罚和危机处理能力，其次是建立外部热点舆论的识别，在发酵前期内部控制，最后是用户反馈机制，可以使用户作为第三方“质检”辅助我们发现存在的内容安全漏洞。

### 过滤能力建设

机器能力：AI模型、敏感词库、白名单、黑名单。

人审能力的建设：

- 培训体系的建设
- 人审的管理
- 人审机制和任务配置体系的简历

高危涉政场景可能对于人审的需求比较大。

机器人工审核一体化：智能引擎审核的同时，提供专业的人工审核服务，高效准确识别不良内容。



### 过滤策略建设

什么时候触发机器/人审核

是否触发二次审核等

配置策略路由，多种能力并联(降低某种能力失效后的快速反应)或串联(高危场景的层层识别)

回调管控策略：对于命中敏感内容如何管控，接入哪些系统治理等。

### 数据池建设

在数据池的建设和积累上，主要为系统的建立和评测的关键指标。主要为5部分：

1是过滤系统，就是机器能力的部署地；
2是人审系统，工单的分配和效率评估；
3是规则和知识库，这一项属于自身能力的沉淀；
4是敏感词库/图片库；
5是高危标注，命中高危标注后流入特殊流程处理，降低舆情风险；

在评测上，目前关键的指标是准确率、召回率、人审效率、系统的每秒查询率、安全场景覆盖率


### 内容安全风险指数指标 

内容安全风险指数则主要从两个角度进行分析，一是自身的排查监管，二是外部环境反馈。

自身的排查监管

自身的排查监管类似于自身的演习与查漏补缺，做好各项风险排查，高效应对各项问题，整体准则为以**低误伤率**、**低漏过率**进行排查，指标应重点关注机器驳回率、人工驳回率以及人工排查效果等。

外部环境反馈 

外部环境反馈一方面是影响程度较高的媒体和政府反馈的内容安全相关的事件及案件数量，另一方面是C端用户的举报量等，整体可根据数量去做模型量化当前的风险(不用太纠结模型多么高大上，能相对体现当前风险即可，但要注意区分不同人群反馈的内容安全风险性不同，比如普通微博用户和大V产生的负向影响肯定不同)。

## 文本内容审核

### 文本审核场景

- 弹幕、评论、聊天
- 个人资料：昵称、简介等
- 聊天机器人（AIGC）：chatgpt很火，催生出一批聊天机器人，但很多人可能诱导机器人违规发言，或者自身发言违规。
- 广告法合规检测（商品素材，广告文案）
- 国际业务多语言检测。

也可以分为：

- 即时通讯：识别用户昵称、签名、群聊消息、群发消息中的不适宜内容。
- 社区论坛：识别用户在社区中的发文、评论中的不适宜内容。
- 视频直播：识别视频、直播中的弹幕、用户评论，实时识别不适宜内容，降低用户人工成本。



### 文本审核标签

文本审核返回的结果：各种标签，以及对应标签的风险置信分数。

大类标签：涉黄、涉政、暴恐、辱骂

细分标签：如涉政的可能还有辱骂领导人、抨击国家体制等等。



- 违禁词库：包含海量历史数据，提供对敏感事件、违规词语及监管要求封禁词语的识别审核能力
- 文本色情：对文本中的色情行为描述、色情资源链接、低俗交友、污秽文爱等内容进行识别
- 违禁违规：对暴力行为、恐怖描述、赌博、毒品、枪支弹药等违禁内容进行识别
- 恶意推广：对文本中带有售卖意向的软文广告，微信、QQ等个人联系方式等违规内容及变体进行识别
- 低俗辱骂：对文本中的侮辱谩骂、人身攻击、消极宣泄等内容进行识别
- 低质灌水：对网络社区常见的乱码、水帖、刷屏等无意义的灌水信息进行识别
- 广告法审核：对广告法中要求的不能出现的违规词进行检测

> 百度文本审核返回结果是标签
>
> 阿里的文本审核增强版返回的是标签 + 风险分数

### 文本审核难点

- 简繁体
- 大小写
- 特殊字符（长得很像数字的非数字字符，比如阿拉伯语、拉丁文的字符）
- 表情符号
- 拼音混合
- 同音字（之前用伞兵来代指傻逼，后来出台政策了不能这样）
- 形近字
- 中文拆字
- 文字乱序
- 文字间隔

### 其他的思考

可以将文本维度的风险转化为主体维度（即账号、设备、IP等）的风险，提升结果处理的准确率及效率。

不仅关注单一样本的风险，也同时关注主体维度的风险。

例如，对于每个账号发送的广告类消息有一定容忍度，但超过限度则进行处罚。

## 图像内容审核

### 图像审核场景



针对不同的场景，可能使用合适的模型效果会更佳

用户发的图片，分辨率大小、差异性比较大等等。

AI生成的图片，规格和大小比较稳定。

视频抽帧的图片

头像，规格大小也比较稳定。



**场景的差异化**：不同应用场景中，对于图像审核存在一定的关注的差异性。

例如电商平台可能更关注商业推广、恶意广告等内容

内容平台可能更关注内容是否健康，有无涉黄、涉政敏感内容。

金融场景可能更关注有无虚假信息、谣言等内容。



### 图像审核标签

图片识别的结果：各种标签，以及对应标签的风险置信分数。

广告、涉黄、涉政、暴恐、违禁、血腥、恶心等、旗帜



### 图像审核难点

### 其他



## 音频内容审核

### 音频审核难点

- 环境影响：车水马龙的场景，七嘴八舌的很多人聊天的场景，工业噪声等。
- 方言：不同方言、口音的影响

## 视频内容审核